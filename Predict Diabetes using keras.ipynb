{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafi\\Anaconda2\\envs\\tensorflowprj\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Pregnancies'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8dfdc16764f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load pima indians dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"diabetes.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# split into input (X) and output (Y) variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#positive diabetes with 1 not 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflowprj\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflowprj\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflowprj\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflowprj\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    736\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Pregnancies'"
     ]
    }
   ],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8] #positive diabetes with 1 not 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 14s 18ms/step - loss: 3.7050 - acc: 0.5977\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.9409 - acc: 0.5885\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.7518 - acc: 0.6432\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.7113 - acc: 0.6628\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6812 - acc: 0.6745\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6503 - acc: 0.6810\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6494 - acc: 0.6719\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6366 - acc: 0.6849\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6242 - acc: 0.6914\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6297 - acc: 0.6784\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.6476 - acc: 0.6706\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6398 - acc: 0.6784\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6258 - acc: 0.6810\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6191 - acc: 0.6953\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.6027 - acc: 0.6914A: 2s - loss: 0.5596 - acc: 0.6 - ETA: 1s\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.5879 - acc: 0.7018\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5854 - acc: 0.7005\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6012 - acc: 0.6849\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5806 - acc: 0.7109\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.5798 - acc: 0.7174\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5687 - acc: 0.7161\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5818 - acc: 0.6966\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5734 - acc: 0.7083\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5680 - acc: 0.7305\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5577 - acc: 0.7344\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5702 - acc: 0.7044\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5556 - acc: 0.7240\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5558 - acc: 0.7292\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5739 - acc: 0.7135\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5607 - acc: 0.7214\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5685 - acc: 0.7161A: 1s - lo\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5636 - acc: 0.7148\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5520 - acc: 0.7201A: 1s - loss: 0\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5492 - acc: 0.7318\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5507 - acc: 0.7201\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5610 - acc: 0.7083\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5349 - acc: 0.7383\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5405 - acc: 0.7227\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5451 - acc: 0.7253\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5445 - acc: 0.7214\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.5435 - acc: 0.7357\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5381 - acc: 0.7409\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5311 - acc: 0.7526\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5333 - acc: 0.7422\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5314 - acc: 0.7539\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5276 - acc: 0.7539\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5320 - acc: 0.7357\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.5330 - acc: 0.7396\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5324 - acc: 0.7500\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5264 - acc: 0.7383\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.5281 - acc: 0.7500\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.5304 - acc: 0.7474\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5387 - acc: 0.7422\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5372 - acc: 0.7240\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.5220 - acc: 0.7513\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5277 - acc: 0.7422\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5307 - acc: 0.7357\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5225 - acc: 0.7526\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5119 - acc: 0.7630\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5334 - acc: 0.7318\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5276 - acc: 0.7409\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5169 - acc: 0.7604\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5419 - acc: 0.7305\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5312 - acc: 0.7422\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5197 - acc: 0.7487A: 0s - loss: 0.5387 - a\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5056 - acc: 0.7539\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5151 - acc: 0.7409\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5128 - acc: 0.7539\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5132 - acc: 0.7487\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5375 - acc: 0.7266\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5176 - acc: 0.7383\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5160 - acc: 0.7500\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5165 - acc: 0.7448\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5101 - acc: 0.7630\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5092 - acc: 0.7591\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5103 - acc: 0.7578A: 0s - loss: 0.5420 - a\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5161 - acc: 0.7630\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5129 - acc: 0.7552A: 0s - loss: 0.5138 - acc: 0.753\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5135 - acc: 0.7513\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5096 - acc: 0.7617\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5052 - acc: 0.7695\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5042 - acc: 0.7578\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4993 - acc: 0.7643\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4968 - acc: 0.7643\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5047 - acc: 0.7487\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5051 - acc: 0.7552\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4988 - acc: 0.7591\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4994 - acc: 0.7643\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5026 - acc: 0.7734\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5108 - acc: 0.7552\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5003 - acc: 0.7539\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5109 - acc: 0.7487\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5013 - acc: 0.7630\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4968 - acc: 0.7695\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5041 - acc: 0.7474A: 0s - loss: 0.5260 - \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4913 - acc: 0.7708A: 0s - loss: 0.4998 - acc: 0.\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4996 - acc: 0.7734A: 0s - loss: 0.47\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4900 - acc: 0.7695\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4913 - acc: 0.7669\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4840 - acc: 0.7826\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4894 - acc: 0.7773\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4983 - acc: 0.7643\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4992 - acc: 0.7656\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4926 - acc: 0.7917\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.5323 - acc: 0.7487\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4911 - acc: 0.7734\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4894 - acc: 0.7773\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4971 - acc: 0.7773\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4864 - acc: 0.7760\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4911 - acc: 0.7656\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4853 - acc: 0.7799\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4887 - acc: 0.7760\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4978 - acc: 0.7695A: 0s - loss: 0.5171 - acc\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4922 - acc: 0.7656A\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4907 - acc: 0.7813\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4925 - acc: 0.7721\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4894 - acc: 0.7643\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4883 - acc: 0.7799\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4822 - acc: 0.7682\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4936 - acc: 0.7799\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4919 - acc: 0.7786\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4858 - acc: 0.7826A: 0s - loss: 0.4838 - acc:\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4803 - acc: 0.7721\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4837 - acc: 0.7786\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4854 - acc: 0.7813\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4806 - acc: 0.7760A: 0s - loss: 0.4706 \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4885 - acc: 0.7708A: 1s - loss: 0.5231 - acc: - ETA: 0s - loss: 0.5065\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4725 - acc: 0.7786\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4813 - acc: 0.7760\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4727 - acc: 0.7891\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4824 - acc: 0.7721\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4832 - acc: 0.7786A: 1s - loss: 0.49\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4813 - acc: 0.7669\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4845 - acc: 0.7773\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4771 - acc: 0.7773\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4727 - acc: 0.7865\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4682 - acc: 0.7786\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4811 - acc: 0.7813\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4642 - acc: 0.7943\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4810 - acc: 0.7878\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4732 - acc: 0.7813\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4831 - acc: 0.7695A: 0s - loss: 0.4784 - acc: 0\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4754 - acc: 0.7708\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4759 - acc: 0.7734\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4878 - acc: 0.7669\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4920 - acc: 0.7682\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4821 - acc: 0.7839\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4704 - acc: 0.7747\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4740 - acc: 0.7669\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4754 - acc: 0.7799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2175a96e5c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 426us/step\n",
      "\n",
      "acc: 79.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "[[0.89523166]\n",
      " [0.18851131]\n",
      " [0.8829252 ]\n",
      " [0.16523999]\n",
      " [0.67058706]\n",
      " [0.30959103]\n",
      " [0.30711716]\n",
      " [0.4768293 ]\n",
      " [0.95244426]\n",
      " [0.1121918 ]\n",
      " [0.23054098]\n",
      " [0.9184908 ]\n",
      " [0.54626316]\n",
      " [0.9432848 ]\n",
      " [0.84585077]\n",
      " [0.29491505]\n",
      " [0.42803925]\n",
      " [0.36787584]\n",
      " [0.52241385]\n",
      " [0.39288697]\n",
      " [0.46975708]\n",
      " [0.3798045 ]\n",
      " [0.92254335]\n",
      " [0.28604054]\n",
      " [0.8114578 ]\n",
      " [0.7677037 ]\n",
      " [0.83421326]\n",
      " [0.21085453]\n",
      " [0.16395748]\n",
      " [0.3220095 ]\n",
      " [0.31886485]\n",
      " [0.68345344]\n",
      " [0.15491465]\n",
      " [0.06025224]\n",
      " [0.7512047 ]\n",
      " [0.59300303]\n",
      " [0.7650337 ]\n",
      " [0.6583581 ]\n",
      " [0.13492158]\n",
      " [0.79569286]\n",
      " [0.566015  ]\n",
      " [0.7136469 ]\n",
      " [0.23343533]\n",
      " [0.77078587]\n",
      " [0.8201566 ]\n",
      " [0.99455655]\n",
      " [0.7350676 ]\n",
      " [0.08441804]\n",
      " [0.4070427 ]\n",
      " [0.20727749]\n",
      " [0.15678282]\n",
      " [0.14072901]\n",
      " [0.12930149]\n",
      " [0.9123453 ]\n",
      " [0.88074815]\n",
      " [0.16144645]\n",
      " [0.90370953]\n",
      " [0.20192759]\n",
      " [0.83165765]\n",
      " [0.23410276]\n",
      " [0.09148656]\n",
      " [0.7178538 ]\n",
      " [0.08130828]\n",
      " [0.6735512 ]\n",
      " [0.60304534]\n",
      " [0.28595963]\n",
      " [0.33758512]\n",
      " [0.4721265 ]\n",
      " [0.03442892]\n",
      " [0.50356054]\n",
      " [0.26773646]\n",
      " [0.6909498 ]\n",
      " [0.7560789 ]\n",
      " [0.36313647]\n",
      " [0.06936965]\n",
      " [0.27351925]\n",
      " [0.12779458]\n",
      " [0.20845227]\n",
      " [0.997686  ]\n",
      " [0.22306041]\n",
      " [0.39323902]\n",
      " [0.0501148 ]\n",
      " [0.07732577]\n",
      " [0.1076775 ]\n",
      " [0.47802857]\n",
      " [0.3033708 ]\n",
      " [0.60877985]\n",
      " [0.24111575]\n",
      " [0.8100498 ]\n",
      " [0.19386865]\n",
      " [0.11256168]\n",
      " [0.38871852]\n",
      " [0.12562606]\n",
      " [0.14588827]\n",
      " [0.1637816 ]\n",
      " [0.71038514]\n",
      " [0.15097825]\n",
      " [0.19115171]\n",
      " [0.1968891 ]\n",
      " [0.42294344]\n",
      " [0.8609564 ]\n",
      " [0.56474614]\n",
      " [0.06878123]\n",
      " [0.02458899]\n",
      " [0.28872153]\n",
      " [0.45197427]\n",
      " [0.01122055]\n",
      " [0.7781151 ]\n",
      " [0.11265968]\n",
      " [0.03675045]\n",
      " [0.72881216]\n",
      " [0.885129  ]\n",
      " [0.02378169]\n",
      " [0.2612    ]\n",
      " [0.8957339 ]\n",
      " [0.6447419 ]\n",
      " [0.5671742 ]\n",
      " [0.46105126]\n",
      " [0.2200908 ]\n",
      " [0.040073  ]\n",
      " [0.9778596 ]\n",
      " [0.20546773]\n",
      " [0.24951582]\n",
      " [0.06579747]\n",
      " [0.22925371]\n",
      " [0.838273  ]\n",
      " [0.3866792 ]\n",
      " [0.38200518]\n",
      " [0.33902478]\n",
      " [0.10387179]\n",
      " [0.75945747]\n",
      " [0.85346913]\n",
      " [0.7775472 ]\n",
      " [0.40487376]\n",
      " [0.04368243]\n",
      " [0.46073756]\n",
      " [0.0491769 ]\n",
      " [0.20841892]\n",
      " [0.35674462]\n",
      " [0.47929317]\n",
      " [0.23310019]\n",
      " [0.4373797 ]\n",
      " [0.29740804]\n",
      " [0.5972725 ]\n",
      " [0.6664452 ]\n",
      " [0.0393782 ]\n",
      " [0.17582092]\n",
      " [0.48491222]\n",
      " [0.36031753]\n",
      " [0.13120562]\n",
      " [0.52703756]\n",
      " [0.40778968]\n",
      " [0.81204706]\n",
      " [0.6528828 ]\n",
      " [0.9652887 ]\n",
      " [0.55720806]\n",
      " [0.29905382]\n",
      " [0.33112416]\n",
      " [0.04910433]\n",
      " [0.9001714 ]\n",
      " [0.39661366]\n",
      " [0.45062315]\n",
      " [0.33820745]\n",
      " [0.1673632 ]\n",
      " [0.31734836]\n",
      " [0.47858822]\n",
      " [0.42466253]\n",
      " [0.5545828 ]\n",
      " [0.46050808]\n",
      " [0.12654501]\n",
      " [0.27282017]\n",
      " [0.5733788 ]\n",
      " [0.3399531 ]\n",
      " [0.03032621]\n",
      " [0.04009497]\n",
      " [0.9331309 ]\n",
      " [0.22812207]\n",
      " [0.658094  ]\n",
      " [0.82598114]\n",
      " [0.6907644 ]\n",
      " [0.11705799]\n",
      " [0.290763  ]\n",
      " [0.13154127]\n",
      " [0.18829231]\n",
      " [0.58726203]\n",
      " [0.9403332 ]\n",
      " [0.96243453]\n",
      " [0.05520472]\n",
      " [0.56848687]\n",
      " [0.5212164 ]\n",
      " [0.24675651]\n",
      " [0.29803726]\n",
      " [0.8446234 ]\n",
      " [0.69355696]\n",
      " [0.27712333]\n",
      " [0.6545411 ]\n",
      " [0.23678158]\n",
      " [0.11056199]\n",
      " [0.41012302]\n",
      " [0.6858798 ]\n",
      " [0.20127204]\n",
      " [0.4836396 ]\n",
      " [0.38979638]\n",
      " [0.0306637 ]\n",
      " [0.6844416 ]\n",
      " [0.2448008 ]\n",
      " [0.9275297 ]\n",
      " [0.652186  ]\n",
      " [0.2000116 ]\n",
      " [0.83101916]\n",
      " [0.17442161]\n",
      " [0.44392362]\n",
      " [0.9172541 ]\n",
      " [0.67433023]\n",
      " [0.60563725]\n",
      " [0.88065827]\n",
      " [0.4363728 ]\n",
      " [0.6290412 ]\n",
      " [0.37501436]\n",
      " [0.618373  ]\n",
      " [0.6969167 ]\n",
      " [0.6227969 ]\n",
      " [0.30257848]\n",
      " [0.89607626]\n",
      " [0.09109329]\n",
      " [0.03095697]\n",
      " [0.20371577]\n",
      " [0.9237007 ]\n",
      " [0.92435443]\n",
      " [0.08245554]\n",
      " [0.8348175 ]\n",
      " [0.7581504 ]\n",
      " [0.02035583]\n",
      " [0.5636204 ]\n",
      " [0.02752123]\n",
      " [0.97302836]\n",
      " [0.8668817 ]\n",
      " [0.98474693]\n",
      " [0.76126176]\n",
      " [0.10803455]\n",
      " [0.11491188]\n",
      " [0.21936934]\n",
      " [0.6238991 ]\n",
      " [0.63033086]\n",
      " [0.5259817 ]\n",
      " [0.9477838 ]\n",
      " [0.67768615]\n",
      " [0.5831871 ]\n",
      " [0.76777804]\n",
      " [0.1278529 ]\n",
      " [0.5008913 ]\n",
      " [0.24741603]\n",
      " [0.02955417]\n",
      " [0.10779714]\n",
      " [0.61821985]\n",
      " [0.15285413]\n",
      " [0.32689184]\n",
      " [0.23012516]\n",
      " [0.70496637]\n",
      " [0.9051596 ]\n",
      " [0.8731907 ]\n",
      " [0.8488684 ]\n",
      " [0.1677428 ]\n",
      " [0.42877325]\n",
      " [0.621352  ]\n",
      " [0.09931052]\n",
      " [0.9933795 ]\n",
      " [0.44474748]\n",
      " [0.2524414 ]\n",
      " [0.72411287]\n",
      " [0.5484471 ]\n",
      " [0.04730794]\n",
      " [0.30847648]\n",
      " [0.01149351]\n",
      " [0.30530208]\n",
      " [0.02149667]\n",
      " [0.41991413]\n",
      " [0.23140393]\n",
      " [0.1374887 ]\n",
      " [0.29551712]\n",
      " [0.6409439 ]\n",
      " [0.7232437 ]\n",
      " [0.47553432]\n",
      " [0.74134904]\n",
      " [0.27564937]\n",
      " [0.6186779 ]\n",
      " [0.83740103]\n",
      " [0.36259407]\n",
      " [0.07603277]\n",
      " [0.07444356]\n",
      " [0.01500155]\n",
      " [0.2713225 ]\n",
      " [0.4574361 ]\n",
      " [0.5507117 ]\n",
      " [0.12314395]\n",
      " [0.7704309 ]\n",
      " [0.7145766 ]\n",
      " [0.3227073 ]\n",
      " [0.71841246]\n",
      " [0.11335305]\n",
      " [0.9819244 ]\n",
      " [0.6541355 ]\n",
      " [0.05243805]\n",
      " [0.30871743]\n",
      " [0.46757272]\n",
      " [0.359095  ]\n",
      " [0.84931886]\n",
      " [0.33839232]\n",
      " [0.33641824]\n",
      " [0.48087585]\n",
      " [0.35471788]\n",
      " [0.24853751]\n",
      " [0.60879636]\n",
      " [0.4390084 ]\n",
      " [0.686563  ]\n",
      " [0.30951244]\n",
      " [0.03544325]\n",
      " [0.79307073]\n",
      " [0.43956852]\n",
      " [0.7984504 ]\n",
      " [0.48671833]\n",
      " [0.17595287]\n",
      " [0.43871334]\n",
      " [0.64388704]\n",
      " [0.11411147]\n",
      " [0.5391191 ]\n",
      " [0.45190883]\n",
      " [0.9319516 ]\n",
      " [0.15191585]\n",
      " [0.07369117]\n",
      " [0.725315  ]\n",
      " [0.16405298]\n",
      " [0.8945276 ]\n",
      " [0.33573008]\n",
      " [0.12909065]\n",
      " [0.7010115 ]\n",
      " [0.1852044 ]\n",
      " [0.4728299 ]\n",
      " [0.78307205]\n",
      " [0.8968705 ]\n",
      " [0.33909577]\n",
      " [0.0727742 ]\n",
      " [0.16231146]\n",
      " [0.38551962]\n",
      " [0.17478727]\n",
      " [0.31477398]\n",
      " [0.62666416]\n",
      " [0.3787366 ]\n",
      " [0.21180375]\n",
      " [0.71706736]\n",
      " [0.29531112]\n",
      " [0.4076011 ]\n",
      " [0.12756646]\n",
      " [0.0731644 ]\n",
      " [0.18384154]\n",
      " [0.8079656 ]\n",
      " [0.60153586]\n",
      " [0.6272359 ]\n",
      " [0.18722361]\n",
      " [0.7899977 ]\n",
      " [0.83860755]\n",
      " [0.3605753 ]\n",
      " [0.27836242]\n",
      " [0.45219886]\n",
      " [0.5957722 ]\n",
      " [0.49355665]\n",
      " [0.45911673]\n",
      " [0.14125493]\n",
      " [0.06108116]\n",
      " [0.40035218]\n",
      " [0.82292104]\n",
      " [0.19016857]\n",
      " [0.12468353]\n",
      " [0.3415812 ]\n",
      " [0.5739872 ]\n",
      " [0.9278155 ]\n",
      " [0.11242497]\n",
      " [0.16362593]\n",
      " [0.8124902 ]\n",
      " [0.06727269]\n",
      " [0.27641347]\n",
      " [0.11971878]\n",
      " [0.2325622 ]\n",
      " [0.14440295]\n",
      " [0.39576948]\n",
      " [0.18747956]\n",
      " [0.50103676]\n",
      " [0.4421793 ]\n",
      " [0.795121  ]\n",
      " [0.3063643 ]\n",
      " [0.4712629 ]\n",
      " [0.93314046]\n",
      " [0.43070054]\n",
      " [0.27989754]\n",
      " [0.7379807 ]\n",
      " [0.5212558 ]\n",
      " [0.57746315]\n",
      " [0.2956825 ]\n",
      " [0.10121067]\n",
      " [0.89112717]\n",
      " [0.34853643]\n",
      " [0.24806365]\n",
      " [0.16823293]\n",
      " [0.23432855]\n",
      " [0.8701459 ]\n",
      " [0.4970565 ]\n",
      " [0.47284198]\n",
      " [0.1806616 ]\n",
      " [0.9350536 ]\n",
      " [0.8459612 ]\n",
      " [0.15619603]\n",
      " [0.3211889 ]\n",
      " [0.3555499 ]\n",
      " [0.16221425]\n",
      " [0.48133057]\n",
      " [0.6998764 ]\n",
      " [0.20948766]\n",
      " [0.60208136]\n",
      " [0.09677711]\n",
      " [0.58058953]\n",
      " [0.27812514]\n",
      " [0.19206195]\n",
      " [0.18166709]\n",
      " [0.23359865]\n",
      " [0.7225721 ]\n",
      " [0.79954034]\n",
      " [0.07815433]\n",
      " [0.84585065]\n",
      " [0.2801232 ]\n",
      " [0.34043345]\n",
      " [0.25375   ]\n",
      " [0.2604283 ]\n",
      " [0.08683655]\n",
      " [0.37145424]\n",
      " [0.29421127]\n",
      " [0.9950663 ]\n",
      " [0.7387293 ]\n",
      " [0.6059045 ]\n",
      " [0.09907263]\n",
      " [0.35932133]\n",
      " [0.6914604 ]\n",
      " [0.0688365 ]\n",
      " [0.41887438]\n",
      " [0.5861951 ]\n",
      " [0.56284124]\n",
      " [0.99970275]\n",
      " [0.1613221 ]\n",
      " [0.17570832]\n",
      " [0.07332841]\n",
      " [0.15962984]\n",
      " [0.15677002]\n",
      " [0.4503133 ]\n",
      " [0.26531014]\n",
      " [0.00316389]\n",
      " [0.30238616]\n",
      " [0.93605036]\n",
      " [0.09798673]\n",
      " [0.1534242 ]\n",
      " [0.9082094 ]\n",
      " [0.04822818]\n",
      " [0.19942893]\n",
      " [0.09687026]\n",
      " [0.12956373]\n",
      " [0.2592389 ]\n",
      " [0.27925876]\n",
      " [0.38613537]\n",
      " [0.07285707]\n",
      " [0.2184354 ]\n",
      " [0.3581059 ]\n",
      " [0.6070365 ]\n",
      " [0.28252345]\n",
      " [0.25642204]\n",
      " [0.56597894]\n",
      " [0.5322495 ]\n",
      " [0.3726963 ]\n",
      " [0.4768678 ]\n",
      " [0.44531372]\n",
      " [0.45791578]\n",
      " [0.07788627]\n",
      " [0.4655573 ]\n",
      " [0.7145338 ]\n",
      " [0.13782509]\n",
      " [0.06651761]\n",
      " [0.12383303]\n",
      " [0.99436015]\n",
      " [0.5091222 ]\n",
      " [0.6451933 ]\n",
      " [0.7796491 ]\n",
      " [0.25048158]\n",
      " [0.72748643]\n",
      " [0.16654326]\n",
      " [0.21271296]\n",
      " [0.24710879]\n",
      " [0.60108703]\n",
      " [0.07279615]\n",
      " [0.35046354]\n",
      " [0.35286874]\n",
      " [0.1278689 ]\n",
      " [0.8673618 ]\n",
      " [0.7787485 ]\n",
      " [0.07473034]\n",
      " [0.15726107]\n",
      " [0.89131314]\n",
      " [0.2596915 ]\n",
      " [0.30359814]\n",
      " [0.18795137]\n",
      " [0.49892408]\n",
      " [0.39659217]\n",
      " [0.24426201]\n",
      " [0.08101922]\n",
      " [0.4474435 ]\n",
      " [0.39235625]\n",
      " [0.03342097]\n",
      " [0.22298978]\n",
      " [0.35588506]\n",
      " [0.7033827 ]\n",
      " [0.8410238 ]\n",
      " [0.5979202 ]\n",
      " [0.26288858]\n",
      " [0.69509786]\n",
      " [0.08591395]\n",
      " [0.36544406]\n",
      " [0.21091518]\n",
      " [0.7937927 ]\n",
      " [0.5472368 ]\n",
      " [0.16595319]\n",
      " [0.23673294]\n",
      " [0.28724924]\n",
      " [0.35227218]\n",
      " [0.315491  ]\n",
      " [0.3962191 ]\n",
      " [0.49098027]\n",
      " [0.02270779]\n",
      " [0.2288076 ]\n",
      " [0.10944187]\n",
      " [0.97609586]\n",
      " [0.16544406]\n",
      " [0.00101887]\n",
      " [0.35965797]\n",
      " [0.5036605 ]\n",
      " [0.69145983]\n",
      " [0.44551906]\n",
      " [0.37318516]\n",
      " [0.03267581]\n",
      " [0.11422772]\n",
      " [0.85930943]\n",
      " [0.8854956 ]\n",
      " [0.45866352]\n",
      " [0.24901997]\n",
      " [0.58370394]\n",
      " [0.12879285]\n",
      " [0.24326082]\n",
      " [0.06205842]\n",
      " [0.04831831]\n",
      " [0.19921501]\n",
      " [0.7268608 ]\n",
      " [0.15862966]\n",
      " [0.10969339]\n",
      " [0.5600387 ]\n",
      " [0.2923768 ]\n",
      " [0.55728793]\n",
      " [0.7530334 ]\n",
      " [0.15327731]\n",
      " [0.10418835]\n",
      " [0.14326906]\n",
      " [0.2631892 ]\n",
      " [0.07421849]\n",
      " [0.61108667]\n",
      " [0.7722964 ]\n",
      " [0.4346667 ]\n",
      " [0.19935782]\n",
      " [0.09637686]\n",
      " [0.06980942]\n",
      " [0.20101796]\n",
      " [0.48785374]\n",
      " [0.08935592]\n",
      " [0.6296687 ]\n",
      " [0.6802252 ]\n",
      " [0.70029825]\n",
      " [0.9292673 ]\n",
      " [0.74198973]\n",
      " [0.31951615]\n",
      " [0.31143403]\n",
      " [0.4645178 ]\n",
      " [0.8563327 ]\n",
      " [0.22805485]\n",
      " [0.8276501 ]\n",
      " [0.31301272]\n",
      " [0.85008836]\n",
      " [0.1165297 ]\n",
      " [0.6937286 ]\n",
      " [0.29129392]\n",
      " [0.5886511 ]\n",
      " [0.2874161 ]\n",
      " [0.737151  ]\n",
      " [0.5797512 ]\n",
      " [0.18120006]\n",
      " [0.23731178]\n",
      " [0.8066191 ]\n",
      " [0.4732595 ]\n",
      " [0.13316888]\n",
      " [0.25655386]\n",
      " [0.19780584]\n",
      " [0.70620245]\n",
      " [0.7470538 ]\n",
      " [0.57998   ]\n",
      " [0.72614187]\n",
      " [0.04304404]\n",
      " [0.5339999 ]\n",
      " [0.2778277 ]\n",
      " [0.36305487]\n",
      " [0.81338114]\n",
      " [0.8543003 ]\n",
      " [0.2684077 ]\n",
      " [0.8356308 ]\n",
      " [0.21407132]\n",
      " [0.17138913]\n",
      " [0.04855414]\n",
      " [0.6731358 ]\n",
      " [0.9620606 ]\n",
      " [0.3345411 ]\n",
      " [0.2904774 ]\n",
      " [0.93174165]\n",
      " [0.14729716]\n",
      " [0.29484892]\n",
      " [0.01792881]\n",
      " [0.2449762 ]\n",
      " [0.38444105]\n",
      " [0.56948155]\n",
      " [0.14102305]\n",
      " [0.60311365]\n",
      " [0.15651567]\n",
      " [0.33263028]\n",
      " [0.24878174]\n",
      " [0.36067072]\n",
      " [0.55933726]\n",
      " [0.34027547]\n",
      " [0.14888637]\n",
      " [0.36308673]\n",
      " [0.01912823]\n",
      " [0.13817951]\n",
      " [0.515353  ]\n",
      " [0.69564986]\n",
      " [0.20494203]\n",
      " [0.37439793]\n",
      " [0.69789433]\n",
      " [0.7021398 ]\n",
      " [0.99079305]\n",
      " [0.68186253]\n",
      " [0.16400738]\n",
      " [0.2664844 ]\n",
      " [0.38854882]\n",
      " [0.11280748]\n",
      " [0.52915215]\n",
      " [0.22881283]\n",
      " [0.7042245 ]\n",
      " [0.31973726]\n",
      " [0.6291068 ]\n",
      " [0.48615888]\n",
      " [0.15323366]\n",
      " [0.78375894]\n",
      " [0.99857724]\n",
      " [0.81788194]\n",
      " [0.83988994]\n",
      " [0.5947599 ]\n",
      " [0.28261518]\n",
      " [0.33108026]\n",
      " [0.6397329 ]\n",
      " [0.6522317 ]\n",
      " [0.47047737]\n",
      " [0.87461215]\n",
      " [0.27185455]\n",
      " [0.11183095]\n",
      " [0.25850716]\n",
      " [0.03070803]\n",
      " [0.9110549 ]\n",
      " [0.6996354 ]\n",
      " [0.29929525]\n",
      " [0.65786254]\n",
      " [0.34392583]\n",
      " [0.03402468]\n",
      " [0.98349935]\n",
      " [0.20545627]\n",
      " [0.401663  ]\n",
      " [0.02346425]\n",
      " [0.40794957]\n",
      " [0.3847224 ]\n",
      " [0.4182294 ]\n",
      " [0.4281238 ]\n",
      " [0.6700674 ]\n",
      " [0.35972548]\n",
      " [0.71601015]\n",
      " [0.31409922]\n",
      " [0.812312  ]\n",
      " [0.17883036]\n",
      " [0.7646008 ]\n",
      " [0.7382125 ]\n",
      " [0.5620513 ]\n",
      " [0.25276744]\n",
      " [0.530172  ]\n",
      " [0.3661362 ]\n",
      " [0.71671444]\n",
      " [0.8668223 ]\n",
      " [0.41243505]\n",
      " [0.3053935 ]\n",
      " [0.12973452]\n",
      " [0.20937003]\n",
      " [0.48774442]\n",
      " [0.86004794]\n",
      " [0.2837059 ]\n",
      " [0.5551019 ]\n",
      " [0.38145334]\n",
      " [0.73905176]\n",
      " [0.42628273]\n",
      " [0.23889019]\n",
      " [0.90087014]\n",
      " [0.7784893 ]\n",
      " [0.1558845 ]\n",
      " [0.45462748]\n",
      " [0.36806306]\n",
      " [0.1450861 ]\n",
      " [0.35766807]\n",
      " [0.7503978 ]\n",
      " [0.39098662]\n",
      " [0.21105455]\n",
      " [0.36878878]\n",
      " [0.29187503]\n",
      " [0.18720861]\n",
      " [0.4007276 ]\n",
      " [0.31330514]\n",
      " [0.19078255]\n",
      " [0.26388475]\n",
      " [0.8020751 ]\n",
      " [0.37604934]\n",
      " [0.16181903]\n",
      " [0.26481816]\n",
      " [0.22674409]\n",
      " [0.245297  ]\n",
      " [0.22294943]\n",
      " [0.40965942]\n",
      " [0.7770218 ]\n",
      " [0.45548964]\n",
      " [0.2845235 ]\n",
      " [0.66010565]\n",
      " [0.8551391 ]\n",
      " [0.34253913]\n",
      " [0.4801099 ]\n",
      " [0.06043134]\n",
      " [0.8155469 ]\n",
      " [0.7126342 ]\n",
      " [0.63975143]\n",
      " [0.09427922]\n",
      " [0.24384546]\n",
      " [0.7351716 ]\n",
      " [0.8482343 ]\n",
      " [0.43919054]\n",
      " [0.45725697]\n",
      " [0.5750808 ]\n",
      " [0.270012  ]\n",
      " [0.90212154]\n",
      " [0.12361793]\n",
      " [0.90977216]\n",
      " [0.2794996 ]\n",
      " [0.9026494 ]\n",
      " [0.31841457]\n",
      " [0.4975442 ]\n",
      " [0.6137048 ]\n",
      " [0.10123669]]\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(len(rounded))\n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
